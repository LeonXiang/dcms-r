::: {.content-hidden}
{{< include ../latex-header.tex >}}
:::

# Introduction {#sec-introduction}

## Recap of Train Ch. 1

Train denotes the outcome in any given situation as $y$, determined by some observable factors collected in the vector $\x$ and some unobservable factors collected in the vector $\beps$. The factors ($\x$ and $\beps$) relate to the agent's choice ($y$) through a function $y = h(\x, \beps)$. We assume for the moment that we know $h(\cdot)$ and that $\x$ and $\beps$ are length-one vectors (i.e., scalars) denoted $x$ and $\varepsilon$.

Since we do not observe $\varepsilon$, we can't predit $y$ exactly. Instead, we focus on the probability of $y$, that is:

$$
\begin{align}
p(y|x) 
&= \Pr \left( \varepsilon \textrm{ such that } h(x,\varepsilon)=y \right) \\
&= \Pr \left( I \left[ h(x,\varepsilon)=y \right] = 1 \right) \\
&= \int I \left[ h(x,\varepsilon)=y \right] f(\varepsilon) \, d\varepsilon
\end{align}
$$ {#eq-int_indicator}

For certain special choices of $h$ and $f$, a closed-form expression for the integral is available.[^1] But more generally, for almost any choice of $h$ and $f$, we can approximate the integral through simulation. Train provides psuedo code on how to do so:

1. Take a draw of $\varepsilon$ from $f(\varepsilon)$. Label this draw $\varepsilon^1$, where the superscript denotes that itis the first draw.
2. Determine whether $h(x,\varepsilon^1) = y$ with this value of $\varepsilon$. If so, create $I^1=1$; otherwise set $I^1=0$.
3. Repeat steps 1 and 2 many times, for a total of $R$ draws. The indicator for each draw is laveled $I^r$ for $r=1, \ldots, R$.

[^1]: In this context, a _closed-form expression_ means a way of writing the integral so that the anti-derivative sign is not part of solution. For example, the closed for expression of $\int x \, dx$ is $x^2/2$ plus some constant. We will see later that the Extreme Value distribution is often chosen for $f$ predominently because it leads to a closed for expression for the choice probability $p(y|x)$.

## A Simple Example {#sec-simple_example}

Let's set up a toy example to demonstrate how simulation can approximate the integral. Suppose $x=0.5$ and $\varepsilon$ is uniformly distributed between $-1$ and $1$. Define $h(x, \varepsilon)$ to be:

$$
h(x, \varepsilon) = 
    \begin{cases}
        0  & \text{if } x + \varepsilon < 0 \\
        1  & \text{if } x + \varepsilon \in [0,1] \\
        2  & \text{if } x + \varepsilon > 1
    \end{cases}
$$ {#eq-h_uniform}

We'll focus on the outcome $y=2$. You can probably intuit that the $p(y=2 | x) = 0.25$ since only one quarter of the time will $\varepsilon$ be sufficiently positive to make $x + \varepsilon > 1$. Nevertheless, let's approximate the integral representation of $p(y=2|x)$ through simulation to ensure we understand the process.

To walk you through the code, we first set a seed so that the pseudo-random numbers generated by `runif()` can be replicated exactly each time the code is run (even on different computers). We then specify that we will use 1,000 draws in the simulation and we create an vector `I` to hold our results. The simulation occurs via a `for()` loop where each time through the loop we take a draw of $\varepsilon$, calculate $0.5 + \varepsilon$ and check whether that sum is greater than one. If so, then $h(x,\varepsilon)=2$ matching the value of $y$ for the choice probability we want to assess ($p(y=2|x)$) and thus we store a $1$ in the $r^\textrm{th}$ position of `I`; otherwise we store a 0. 

```{r}
set.seed(1234)

R <- 1000
I <- vector(length=R)

for(r in 1:R) {
    eps  <- runif(1, min=-1, max=1)
    h    <- 0.5 + eps 
    I[r] <- as.integer(h > 1)
}
mean(I)
```

The simulated value `r format(mean(I), digits=2)` is close to exact value 0.25 and can be made closer by increasing the number of draws used in the simulation.

R users will recognize that we can simplify the code by taking advantage of R's vectorized functions and it's conversion of boolean values to 0/1 when used in mathematical operations. Here is a shorter implementation of the simulation. Whether it's "better" code is a matter of preference.

```{r}
set.seed(1234)
R <- 1000
mean( runif(R, min=-1, max=1) + 0.5 > 1 )
```

That's it. If you can generate pseudo-random draws from the density $f$ and you know $h$, this simulation requires only a handful of lines of code.

## A Binary Logit Model Example {#sec-binary_logit}

